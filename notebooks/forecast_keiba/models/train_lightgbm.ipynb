{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-21 10:46:56,589 - kedro.io.data_catalog - INFO - Loading data from `race_results_df_processed` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "# kedro\n",
    "from kedro.framework.context import load_context\n",
    "proj_path = '../../../' \n",
    "context = load_context(proj_path)\n",
    "race_results_df_processed = catalog.load(\"race_results_df_processed\")\n",
    "parameters = context.params\n",
    "\n",
    "# import from src\n",
    "sys.path.append(\"./../../../src/forecast_keiba/\")\n",
    "from models.train_lightgbm import split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import文\n",
    "メイン関数実行のため"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime as dt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メイン関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(race_results_df_processed, parameters):\n",
    "    print('start train_lr')\n",
    "    race_results_df_processed.sort_values('date', ascending=False)\n",
    "    df = race_results_df_processed[(race_results_df_processed['date'] > dt.datetime(2010,1,1)) & (race_results_df_processed['date'] < dt.datetime(2019,12,31))]\n",
    "    df['rank'] = df['着順'].map(lambda x: 1 if x < 6 else (3 if x > 11 else 2))\n",
    "    df.to_pickle('../../../data/processed/train_data.pickle')\n",
    "    train,test = split_data(df,0.3)\n",
    "    rank_1 = train['rank'].value_counts()[1]\n",
    "    rank_2 = train['rank'].value_counts()[2]\n",
    "    rank_3 = train['rank'].value_counts()[3]\n",
    "    rus = RandomUnderSampler(sampling_strategy={1:rank_1,2:rank_2,3:rank_3},random_state=71)\n",
    "\n",
    "    X_train = train.drop(['着順','date','rank'],axis=1)\n",
    "    y_train = train['rank']\n",
    "    X_test = test.drop(['着順','date','rank'],axis=1)\n",
    "    y_test = test['rank']\n",
    "\n",
    "    X_train_rus,y_train_rus = rus.fit_sample(X_train,y_train)\n",
    "    \n",
    "    params = {\n",
    "    \"num_leaves\": 64,\n",
    "    \"n_estimators\": 80,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 100,\n",
    "    \"max_depth\": 24,\n",
    "    }\n",
    "\n",
    "    model_lightgbm = lgb.LGBMClassifier(**params)\n",
    "    model_lightgbm.fit(X_train_rus.values,y_train_rus.values)\n",
    "\n",
    "    print('train score: ' + str(model_lightgbm.score(X_train,y_train)))\n",
    "    print('test score: ' + str(model_lightgbm.score(X_test,y_test)))\n",
    "    \n",
    "    print('feature importances')\n",
    "    importances = pd.DataFrame(\n",
    "    {\"features\": X_train.columns, \"importance\": model_lightgbm.feature_importances_}\n",
    "    )\n",
    "    print(importances.sort_values(\"importance\", ascending=False)[:20])\n",
    "    pickle.dump(model_lightgbm, open('../../../data/models/model_lightgbm', 'wb'))\n",
    "    \n",
    "    return model_lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train_lr\n",
      "train score: 0.2903225806451613\n",
      "test score: 0.3125\n",
      "feature importances\n",
      "   features  importance\n",
      "0        枠番           0\n",
      "58  peds_41           0\n",
      "67  peds_50           0\n",
      "66  peds_49           0\n",
      "65  peds_48           0\n",
      "64  peds_47           0\n",
      "63  peds_46           0\n",
      "62  peds_45           0\n",
      "61  peds_44           0\n",
      "60  peds_43           0\n",
      "59  peds_42           0\n",
      "57  peds_40           0\n",
      "1        馬番           0\n",
      "56  peds_39           0\n",
      "55  peds_38           0\n",
      "54  peds_37           0\n",
      "53  peds_36           0\n",
      "52  peds_35           0\n",
      "51  peds_34           0\n",
      "50  peds_33           0\n"
     ]
    }
   ],
   "source": [
    "def main(race_results_df_processed, parameters):\n",
    "    return train_lightgbm(race_results_df_processed, parameters)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(race_results_df_processed, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecastkeiba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
