{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ収集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedro.framework.context import load_context\n",
    "proj_path = '../../../' \n",
    "context = load_context(proj_path)\n",
    "# df = catalog.load(\"XXX\")\n",
    "parameters = context.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_scraping_netkeiba_race_results(race_id_list):\n",
    "    \"\"\"\n",
    "    netkeiba.comのレースIDのリストを渡して、それらをまとめて{'レースID', 結果のDataFrame}という形式の辞書型に格納する\n",
    "    ex. race_results['201901010101']\n",
    "        -> df 着順 枠番 馬番 馬名 性齢 斤量 騎手 タイム 着差 単勝 人気 馬体重 調教師 horse_id jockey_id course_id\n",
    "    \"\"\"\n",
    "    race_results_dict = {}\n",
    "    for race_id in race_id_list:\n",
    "        try:\n",
    "            # ベース情報を取ってくる\n",
    "            url = 'https://db.netkeiba.com/race/' + race_id\n",
    "            race_results_dict[race_id] = pd.read_html(url)[0]\n",
    "            \n",
    "            # 詳細情報取得のために、再度対象URLのページを取得する\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            # horse_idを取得する\n",
    "            horse_id_list = []\n",
    "            horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\"a\", attrs={\"href\": re.compile(\"^/horse\")})\n",
    "            for a in horse_a_list:\n",
    "                horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                horse_id_list.append(horse_id[0])\n",
    "\n",
    "            # jockey_idを取得する\n",
    "            jockey_id_list = []\n",
    "            jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "            )\n",
    "            for a in jockey_a_list:\n",
    "                jockey_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                jockey_id_list.append(jockey_id[0])\n",
    "\n",
    "            # horse_idとjockey_idをベースに追加\n",
    "            race_results_dict[race_id][\"horse_id\"] = horse_id_list\n",
    "            race_results_dict[race_id][\"jockey_id\"] = jockey_id_list\n",
    "      \n",
    "            # course_idをベースに追加\n",
    "            race_results_dict[race_id]['course_id'] = [int(race_id[4:6])]*len(horse_id_list)\n",
    "\n",
    "            # course_len, course_type , weather, race_type, ground_state, dateを取得してベースに追加\n",
    "            texts = (\n",
    "                soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[0].text\n",
    "                + soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[1].text\n",
    "            )\n",
    "            info = re.findall(r'\\w+', texts)\n",
    "            for text in info:\n",
    "                if text in [\"芝\", \"ダート\"]:\n",
    "                    race_results_dict[race_id][\"race_type\"] = text\n",
    "                if \"障\" in text:\n",
    "                    race_results_dict[race_id][\"race_type\"] = \"障害\"\n",
    "                if \"m\" in text:\n",
    "                    race_results_dict[race_id][\"course_len\"] = int(re.findall(r\"\\d+\", text)[0])\n",
    "                if text in [\"良\", \"稍重\", \"重\", \"不良\"]:\n",
    "                    race_results_dict[race_id][\"ground_state\"] = text\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    race_results_dict[race_id][\"weather\"] = text\n",
    "                if \"年\" in text:\n",
    "                    race_results_dict[race_id][\"date\"] = text\n",
    "                    race_results_dict[race_id]['date'] = pd.to_datetime(race_results_dict[race_id]['date'],format='%Y年%m月%d日')\n",
    "                # change コース特性追加\n",
    "                if \"右\" in text:\n",
    "                    race_results_dict[race_id][\"course_type\"] = \"right\"\n",
    "                if \"左\" in text:\n",
    "                    race_results_dict[race_id][\"course_type\"] = \"left\"\n",
    "                if \"直線\" in text:\n",
    "                    race_results_dict[race_id][\"course_type\"] = \"straight\"            \n",
    "\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except:\n",
    "            break\n",
    "    return race_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_horse_results(horse_id_list):\n",
    "    horse_results = {}\n",
    "    for horse_id in horse_id_list:\n",
    "        try:\n",
    "            url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "            df = pd.read_html(url)[3]\n",
    "            if df.columns[0]=='受賞歴':\n",
    "                df = pd.read_html(url)[4]\n",
    "            horse_results[horse_id] = df\n",
    "            time.sleep(0.1)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(e)\n",
    "            break\n",
    "        except:\n",
    "            break\n",
    "    return horse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金']]\n",
    "        self.preprocessing()\n",
    "\n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "\n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "\n",
    "        self.horse_results = df\n",
    "\n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "\n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "\n",
    "        average = filtered_df.groupby(level=0)[['着順', '賞金']].mean()\n",
    "        return average.rename(columns={'着順':'着順_{}R'.format(n_samples), '賞金':'賞金_{}R'.format(n_samples)})\n",
    "    # change 馬の最高賞金追加\n",
    "    def max_money(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "            \n",
    "        max_money = filtered_df.groupby(level=0)[['賞金']].max()\n",
    "        return max_money.rename(columns={'賞金':'最高賞金_{}R'.format(n_samples)})\n",
    "\n",
    "    def merge(self, results, date, n_samples='all'):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        merged_df = df.merge(self.average(horse_id_list, date, n_samples), left_on='horse_id',\n",
    "                             right_index=True, how='left').merge(self.max_money(horse_id_list, date, 'all'), left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        return merged_df\n",
    "\n",
    "    def merge_all(self, results, n_samples='all'):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat([self.merge(results, date, n_samples) for date in date_list])\n",
    "        return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mainの中身"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list = []\n",
    "\n",
    "for place in range(1,11):\n",
    "    for kai in range(1,6):\n",
    "        for day in range(1,9):\n",
    "            for r in range(1,13):\n",
    "                race_id = '2019' + str(place).zfill(2) + str(kai).zfill(2) + str(day).zfill(2) + str(r).zfill(2)\n",
    "                race_id_list.append(race_id)\n",
    "# -> ['201901010101', '201901010102', ,,, ]\n",
    "\n",
    "# スクレイピング実行\n",
    "race_results_dict = exec_scraping_netkeiba_race_results(race_id_list[0:parameters[\"scraping_limit\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表として見やすいように、dfのindexにrace idを入れる\n",
    "for key in race_results_dict.keys():\n",
    "    race_results_dict[key].index = [key]*len(race_results_dict[key])\n",
    "\n",
    "# 各レース結果のdfを1つに結合する\n",
    "race_results_df = pd.concat((race_results_dict[key] for key in race_results_dict.keys()),sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 馬の詳細情報を取得する\n",
    "horse_id_list = race_results_df['horse_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_results_dict = scrape_horse_results(horse_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in horse_results_dict:\n",
    "    horse_results_dict[key].index = [key] * len(horse_results_dict[key])\n",
    "df_horse_results = pd.concat([horse_results_dict[key] for key in horse_results_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = HorseResults(df_horse_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 着順_5R, 賞金_5R, 最高賞金_allRを取得してベースに追加\n",
    "race_results_df = hr.merge_all(race_results_df, n_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = catalog.load(\"race_results_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_netkeiba_past(race_results_df):\n",
    "    df = race_results_df.copy()\n",
    "\n",
    "    # データ整形\n",
    "    df = df[~(df['着順'].astype(str).str.contains('\\D'))]\n",
    "    df['着順'] = df['着順'].astype(int)\n",
    "    df['性'] = df['性齢'].map(lambda x:str(x)[0])\n",
    "    df['年齢'] = df['性齢'].map(lambda x:str(x)[1:]).astype(int)\n",
    "    df['体重'] = df['馬体重'].str.split('(',expand = True)[0].astype(int)\n",
    "    df['体重変化'] = df['馬体重'].str.split('(',expand = True)[1].str[:-1].astype(int)\n",
    "    df['単勝'] = df['単勝'].astype(float)\n",
    "\n",
    "    df.drop(['タイム','着差','調教師','性齢','馬体重', 'horse_id', 'jockey_id'],axis = 1,inplace = True)\n",
    "\n",
    "    # 4位より下はまとめる\n",
    "    clip_rank = lambda x: x if x < 4 else 4\n",
    "    df['rank'] = df['着順'].map(clip_rank)\n",
    "\n",
    "    # test['馬名'].value_counts()などでカウントし、数が多そうなのは落とした後、ダミー変数化\n",
    "    df.drop(['着順','馬名','騎手'], axis = 1,inplace = True)\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mainの中身"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df_processed_base = preprocess_netkeiba_past(race_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df_processed_base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecastkeiba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
